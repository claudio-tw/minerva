{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea27168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "\n",
    "from minerva.select import Selector\n",
    "from minerva.iterable_dataset import MyDataset, MyIterableDataset\n",
    "from minerva import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca211820",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b71b994",
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = Path('./data/categorical')\n",
    "pth.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62500056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the synthetis of data\n",
    "n = 50000\n",
    "dx = 10\n",
    "num_relevant = 2\n",
    "feat_sizes = np.random.randint(low=7, high=10, size=(dx))\n",
    "dy = 1 \n",
    "train_size = int(.66 * n)\n",
    "val_size = int(.15 * n)\n",
    "test_size = n - train_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b4157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set metaparameters\n",
    "\n",
    "num_samples = n\n",
    "# The below makes things quite slow; 256 and 3 seem to perform almost as well, but way faster\n",
    "dimension_of_residual_block = 512\n",
    "num_res_layers = 4\n",
    "scaler = 2  # Scaler = 4 did the best so far, scaler=8 diverged\n",
    "batch_size = scaler*2048\n",
    "num_batches = num_samples // batch_size\n",
    "max_epochs =  int(2000*scaler)  # to keep the number of batches constant\n",
    "\n",
    "lr = 1e-5  # scaling that as sqrt(scaler) didn't seem to work\n",
    "emb_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3741376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthesize the data\n",
    "xs = [\n",
    "        np.random.randint(low=0, high=size, size=(n, 1))\n",
    "        for size in feat_sizes\n",
    "]\n",
    "x = np.concatenate(xs, axis=1)\n",
    "expected = np.random.choice(dx, replace=False, size=num_relevant)\n",
    "y = np.zeros(shape=(n,), dtype=int)\n",
    "for f0, f1 in zip(expected[:-1], expected[1:]):\n",
    "    x0 = x[:, f0] / feat_sizes[f0]\n",
    "    x1 = x[:, f1] / feat_sizes[f1]\n",
    "    y += np.array(x0 > x1, dtype=int)\n",
    "    \n",
    "feature_cols = [f'f{n}' for n in range(dx)]\n",
    "float_features = []\n",
    "cat_features = feature_cols\n",
    "targets = [f'y{n}' for n in range(dy)]\n",
    "targets = targets\n",
    "xdf = pd.DataFrame(\n",
    "    x,\n",
    "    columns=feature_cols\n",
    ")\n",
    "ydf = pd.DataFrame(\n",
    "    y,\n",
    "    columns=targets\n",
    ")\n",
    "data = pd.concat((xdf, ydf), axis=1)\n",
    "train_data = data.iloc[:train_size]\n",
    "val_data = data.iloc[train_size: train_size + val_size]\n",
    "test_data = data.iloc[train_size + val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb707af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for the training\n",
    "dn = normalize.DatasetNormalizer(\n",
    "    float_cols=[], categorical_cols=cat_features + targets)\n",
    "train_data = dn.fit_transform(train_data)\n",
    "val_data = dn.transform(val_data)\n",
    "test_data = dn.transform(test_data)\n",
    "\n",
    "train_dataset = MyDataset(\n",
    "    train_data,\n",
    "    float_features,\n",
    "    cat_features,\n",
    "    targets\n",
    ")\n",
    "val_dataset = MyDataset(\n",
    "    val_data,\n",
    "    float_features,\n",
    "    cat_features,\n",
    "    targets\n",
    ")\n",
    "test_dataset = MyDataset(\n",
    "    test_data,\n",
    "    float_features,\n",
    "    cat_features,\n",
    "    targets\n",
    ")\n",
    "\n",
    "train_dataloader = MyIterableDataset(train_dataset, batch_size=batch_size)\n",
    "val_dataloader = MyIterableDataset(val_dataset, batch_size=batch_size)\n",
    "test_dataloader = MyIterableDataset(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdaca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_this(reg_coef: float, load_path=None, wgt_mult=None):\n",
    "    \n",
    "    selector = Selector(\n",
    "        cat_features=cat_features,\n",
    "        float_features=float_features,\n",
    "        targets=targets,\n",
    "        dim1_max=dimension_of_residual_block,\n",
    "        lr=lr,\n",
    "        num_res_layers=num_res_layers,\n",
    "        regularization_coef=reg_coef,\n",
    "        eps=.001,\n",
    "        cat_feat_sizes=feat_sizes,\n",
    "        emb_dim=emb_dim,\n",
    "    )\n",
    "    if load_path is not None:\n",
    "        selector.load_state_dict(torch.load(load_path))\n",
    "\n",
    "    # Set dataloaders\n",
    "    selector.set_loaders(train_dataloader, val_dataloader, test_dataloader)\n",
    "    \n",
    "    selector.enable_projection(wgt_mult=wgt_mult)\n",
    "\n",
    "    # Train the model\n",
    "    logger = TensorBoardLogger(\"tb_logs\", name=\"categorical\")\n",
    "    trainer = pl.Trainer(\n",
    "        gradient_clip_val=0.5,\n",
    "        accelerator=\"auto\",\n",
    "        log_every_n_steps=50,\n",
    "        max_epochs=max_epochs,\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "    trainer.fit(\n",
    "        selector,\n",
    "        train_dataloaders=train_dataloader,\n",
    "        val_dataloaders=val_dataloader\n",
    "    )\n",
    "\n",
    "    final_test_loss = trainer.test(selector)\n",
    "    out = final_test_loss[0]\n",
    "    out[\"selected_features\"] = selector.selected_feature_names()\n",
    "    return out, selector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1048c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "noreg_path = \"./data/categorical/noreg.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892ba9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a long run without reg, to get the MI network right\n",
    "out, selector = run_this(reg_coef=0.0, wgt_mult=None)\n",
    "torch.save(selector.state_dict(), noreg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d325327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now add reg starting from that snapshot\n",
    "# Regularization level appears to have almost no effect as long as it's > 100\n",
    "reg_coefs = [1e5]\n",
    "results = []\n",
    "for reg_coef in reg_coefs:\n",
    "    out, selector = run_this(reg_coef=reg_coef, load_path=noreg_path, wgt_mult=.25)\n",
    "    results.append(out)\n",
    "    results[-1][\"reg_coef\"] = reg_coef\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(\"./data/categorical/results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bbb658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results\n",
    "print(\n",
    "    f'Normalised coefficients of the projection matrix:\\n{selector.normalized_proj()}\\n')\n",
    "print(f'Selected features:\\n{selector.selected_feature_names()}\\n')\n",
    "print(f'Expected features:\\n{expected}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171ee37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Mutual information on train dataset: {float(selector.train_mutual_information())}')\n",
    "print(f'Mutual information on val dataset: {float(selector.val_mutual_information())}')\n",
    "print(f'Mutual information on test dataset: {float(selector.test_mutual_information())}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minerva",
   "language": "python",
   "name": "minerva"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
