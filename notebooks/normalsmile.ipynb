{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffdcbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from minerva import select\n",
    "from minerva.iterable_dataset import MyDataset, MyIterableDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3be4c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(corr: float, number_of_samples: int) -> pd.DataFrame:\n",
    "    cov = np.array([[1., corr], [corr, 1.]])\n",
    "    mean = np.array([.0, .0])\n",
    "    z = multivariate_normal.rvs(\n",
    "        mean=mean,\n",
    "        cov=cov,\n",
    "        size=number_of_samples\n",
    "    )\n",
    "    df = pd.DataFrame(z, columns=['x', 'y'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48db86a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(\n",
    "    corr: float,\n",
    "    number_of_samples: int = 100000,\n",
    "    dimension_of_residual_block: int = 200,\n",
    "    lr: float = 1e-4,\n",
    "    num_res_layers: int = 3,\n",
    "    max_epochs: int = 300,\n",
    "    batch_size: int = 2000,\n",
    "):\n",
    "    n = number_of_samples\n",
    "    train_size = int(.66 * n)\n",
    "    val_size = int(.15 * n)\n",
    "    test_size = n - train_size - val_size\n",
    "    feature_cols = ['x']\n",
    "    float_features = feature_cols\n",
    "    target_cols = ['y']\n",
    "    target_names = target_cols\n",
    "    cat_features = []\n",
    "    exact_mi = - .5 * np.log(1. - corr * corr)\n",
    "    data = sample(corr, number_of_samples)\n",
    "    train_data = data.iloc[:train_size]\n",
    "    val_data = data.iloc[train_size: train_size + val_size]\n",
    "    test_data = data.iloc[train_size + val_size:]\n",
    "    train_dataset = MyDataset(\n",
    "        train_data,\n",
    "        float_features,\n",
    "        cat_features,\n",
    "        target_names\n",
    "    )\n",
    "    val_dataset = MyDataset(\n",
    "        val_data,\n",
    "        float_features,\n",
    "        cat_features,\n",
    "        target_names\n",
    "    )\n",
    "    test_dataset = MyDataset(\n",
    "        test_data,\n",
    "        float_features,\n",
    "        cat_features,\n",
    "        target_names\n",
    "    )\n",
    "    train_dataloader = MyIterableDataset(train_dataset, batch_size=batch_size)\n",
    "    val_dataloader = MyIterableDataset(val_dataset, batch_size=batch_size)\n",
    "    test_dataloader = MyIterableDataset(test_dataset, batch_size=batch_size)\n",
    "    selector = select.Selector(\n",
    "        feature_cols=feature_cols,\n",
    "        target_cols=target_names,\n",
    "        dim1_max=dimension_of_residual_block,\n",
    "        lr=lr,\n",
    "        num_res_layers=num_res_layers,\n",
    "        regularization_coef=0.,\n",
    "        drift_coef=.0,\n",
    "    )\n",
    "    selector.disable_projection()\n",
    "    selector.set_loaders(train_dataloader, val_dataloader, test_dataloader)\n",
    "    logger = TensorBoardLogger(\"tb_logs\", name='normalsmile')\n",
    "    trainer = pl.Trainer(\n",
    "        gradient_clip_val=.5,\n",
    "        accelerator=\"auto\",\n",
    "        log_every_n_steps=10,\n",
    "        max_epochs=max_epochs,\n",
    "        logger=logger,\n",
    "    )\n",
    "    trainer.fit(\n",
    "        selector,\n",
    "        train_dataloaders=train_dataloader,\n",
    "        val_dataloaders=val_dataloader,\n",
    "    )\n",
    "    train_mi = float(selector.train_mutual_information())\n",
    "    val_mi = float(selector.val_mutual_information())\n",
    "    test_mi = float(selector.test_mutual_information())\n",
    "    print('\\n\\n#########################################################################')\n",
    "    print(f'Correlation: {corr}')\n",
    "    print(f'Exact mutual information: {exact_mi}')\n",
    "    print(f'Mutual information on train dataset: {train_mi}')\n",
    "    print(f'Mutual information on val dataset: {val_mi}')\n",
    "    print(f'Mutual information on test dataset: {test_mi}')\n",
    "    res = dict(\n",
    "        exact_mi = exact_mi,\n",
    "        train_mi = train_mi,\n",
    "        val_mi = val_mi,\n",
    "        test_mi = test_mi\n",
    "    )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358883eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.concatenate((np.linspace(-.95, -.01, num=5), np.linspace(.01, .95, num=5)))\n",
    "number_of_samples = 100000\n",
    "\n",
    "dimension_of_residual_block = 100\n",
    "lr = 3e-4\n",
    "num_res_layers = 3\n",
    "max_epochs = 100\n",
    "batch_size = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84cb60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_mis = []\n",
    "train_mis = []\n",
    "val_mis = []\n",
    "test_mis = []\n",
    "for rho in rhos: \n",
    "    res = run(\n",
    "        corr=rho,\n",
    "        number_of_samples=number_of_samples,\n",
    "        dimension_of_residual_block=dimension_of_residual_block,\n",
    "        lr=lr,\n",
    "        num_res_layers=num_res_layers,\n",
    "        max_epochs=max_epochs,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    train_mis.append(res['train_mi'])\n",
    "    val_mis.append(res['val_mi'])\n",
    "    test_mis.append(res['test_mi'])\n",
    "    exact_mis.append(res['exact_mi'])\n",
    "    \n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'exact_mi': exact_mis,\n",
    "        'train_mi': train_mis,\n",
    "        'val_mi': val_mis,\n",
    "        'test_mi': test_mis\n",
    "    },\n",
    "    index=rhos\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eecf3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "rhos = np.linspace(-.95, .95, num=100)\n",
    "exact_mis = - .5 * np.log(1. - rhos * rhos)\n",
    "ax.plot(rhos, exact_mis, label='exact_mi')\n",
    "ax = df[['train_mi', 'test_mi']].plot(\n",
    "    style={\n",
    "           'train_mi': '*--',\n",
    "           'test_mi': '*--'\n",
    "          },\n",
    "    ax=ax\n",
    ")\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444f1ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minerva",
   "language": "python",
   "name": "minerva"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
