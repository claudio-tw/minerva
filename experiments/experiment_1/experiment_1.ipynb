{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802e8c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import itertools\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "from scipy.stats import special_ortho_group\n",
    "\n",
    "import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41064b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 30\n",
    "df = pd.read_csv('data/large.csv')\n",
    "n_samples = len(df)\n",
    "expected_features = np.array([3, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f2a263",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f'f{n}' for n in range(d)]\n",
    "targets = ['y']\n",
    "xdf = df[features]\n",
    "ydf = df[targets]\n",
    "x = xdf.values\n",
    "y = ydf.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cd3f06",
   "metadata": {},
   "source": [
    "## Uncover the dependence between target and features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d035735e",
   "metadata": {},
   "source": [
    "We check that \n",
    "$$\n",
    "y =\n",
    "\\begin{cases}\n",
    "1 & \\text{  if } x_{k_{0}} = x_{k_{1}}\n",
    "\\\\\n",
    "0 & \\text { otherwise},\n",
    "\\end{cases}\n",
    "$$\n",
    "where $k_0 = 3$ and $k_1 = 8$\n",
    "are the expected features.\n",
    "\n",
    "From the thirty features $0, \\dots, 29$ in `df`, our feature selection is exact if it keeps features 3 and 8, and it discards all others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac4fa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(x[:, expected_features[0]] == x[:, expected_features[1]], dtype=int)\n",
    "assert np.all(test == y[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bdea13",
   "metadata": {},
   "source": [
    "## Preliminary check: expected features bear the highest information content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab5e11a",
   "metadata": {},
   "source": [
    "Of all $d \\choose 2$ pairs of features, we check that the expected pair $\\lbrace 3 , 8 \\rbrace$ has the highest mutual information with the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a8e7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 2\n",
    "miscores = {subset: \n",
    "           adjusted_mutual_info_score(tools.onedimlabel(x[:, list(subset)]), y[:, 0])\n",
    "            for subset in itertools.combinations(list(range(d)), l)\n",
    "            \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168eb38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (0,1)\n",
    "mi = 0\n",
    "for k, v in miscores.items():\n",
    "    if v > mi:\n",
    "        s = k\n",
    "        mi = v\n",
    "highest_info = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14eb4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Expected features: {sorted(expected_features)}')\n",
    "print(f'Pair of features with highest information content: {sorted(highest_info)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37502d7",
   "metadata": {},
   "source": [
    "### Selection with marginal 1D ksg mutual info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139b18ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ksgselection, mis = tools.ksgmi(xdf, ydf, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffca204",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Expected features: {sorted(expected_features)}')\n",
    "print(f'Marginal KSG selection: {sorted(ksgselection)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8906000",
   "metadata": {},
   "source": [
    "### Selection with HSIC Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af05a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xfeattype = tools.FeatureType.CATEGORICAL\n",
    "yfeattype = tools.FeatureType.CATEGORICAL\n",
    "hsiclasso_selection = tools.pyhsiclasso(\n",
    "    x, y, xfeattype=xfeattype, yfeattype=yfeattype, n_features=2, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8eb111",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Expected features: {sorted(expected_features)}')\n",
    "print(f'HSIC Lasso selection: {sorted(hsiclasso_selection)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6776b78e",
   "metadata": {},
   "source": [
    "### Selection with Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511abe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arfs.feature_selection import allrelevant\n",
    "from arfs.feature_selection.allrelevant import Leshy\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02901e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 'auto'\n",
    "perc = 95\n",
    "alpha = 0.05\n",
    "importance = \"shap\"\n",
    "two_step = True\n",
    "max_iter = 100\n",
    "random_state = 1234\n",
    "verbose = 0\n",
    "keep_weak = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00081320",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf = pd.DataFrame(x, columns = [f'f{i}' for i in range(d)])\n",
    "yser = pd.Series(y[:, 0], name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f456422",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1, max_depth=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36700a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "leshy = Leshy(\n",
    "    rf,\n",
    "    n_estimators=n_estimators,\n",
    "    perc=perc,\n",
    "    alpha=alpha,\n",
    "    importance=importance,\n",
    "    two_step=two_step,\n",
    "    max_iter=max_iter,\n",
    "    random_state=random_state,\n",
    "    verbose=verbose,\n",
    "    keep_weak=keep_weak,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9613c874",
   "metadata": {},
   "outputs": [],
   "source": [
    "leshy.fit(xdf, yser)\n",
    "leshy_selection = [int(col.replace('f', '')) for col in leshy.selected_features_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9056e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Expected features: {sorted(expected_features)}')\n",
    "print(f'Boruta selection: {sorted(leshy_selection)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44264014",
   "metadata": {},
   "source": [
    "## Selection with Minerva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9e9161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minerva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee2a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [f'f{n}' for n in range(d)]\n",
    "cat_features = feature_cols  # all features are categorical\n",
    "float_features = []  # no feature is float\n",
    "targets = ['y']\n",
    "cat_feat_sizes = 1 + df[cat_features].max().values\n",
    "train_size = int(.75 * n_samples)\n",
    "val_size = int(.225 * n_samples)\n",
    "test_size = n_samples - train_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a783f3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df.iloc[:train_size]\n",
    "val_data = df.iloc[train_size: train_size + val_size]\n",
    "test_data = df.iloc[:-test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56e08f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_of_residual_block = 512 \n",
    "num_res_layers = 4 \n",
    "scaler = 2  \n",
    "batch_size = scaler*1200\n",
    "num_batches = n_samples // batch_size\n",
    "max_epochs = int(2000*scaler)  \n",
    "lr = 5e-6  \n",
    "emb_dim = 4 \n",
    "reg_coef = 1e6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de43a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pack hyperparameters\n",
    "selector_params = dict(\n",
    "    cat_features=cat_features,\n",
    "    float_features=float_features,\n",
    "    targets=targets,\n",
    "    dim1_max=dimension_of_residual_block,\n",
    "    lr=lr,\n",
    "    num_res_layers=num_res_layers,\n",
    "    eps=.001,\n",
    "    cat_feat_sizes=cat_feat_sizes,\n",
    "    emb_dim=emb_dim,\n",
    ")\n",
    "logger_params = dict(\n",
    "    name=\"experiment_1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74d34cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataloaders\n",
    "train_dataloader, val_dataloader, test_dataloader = minerva.feature_selection.dataloaders(\n",
    "    train_data=train_data,\n",
    "    val_data=val_data,\n",
    "    test_data=test_data,\n",
    "    float_features=float_features,\n",
    "    categorical_features=cat_features,\n",
    "    targets=targets,\n",
    "    batch_size=batch_size,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0ad357",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a7c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First pass: No regularisation\n",
    "noreg_path = 'data/noreg.model'\n",
    "out, selector = minerva.feature_selection.train(\n",
    "    selector_params=selector_params,\n",
    "    logger_params=logger_params,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    reg_coef=.0,\n",
    "    projection_init=.20,\n",
    "    disable_projection=False,\n",
    "    max_epochs=max_epochs,\n",
    "    load_path=None\n",
    ")   \n",
    "logs.append(out)\n",
    "torch.save(selector.state_dict(), noreg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda41b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_segment_path = noreg_path\n",
    "# Second pass: Apply regularisation\n",
    "for segment in range(5):\n",
    "    out, selector = minerva.feature_selection.train(\n",
    "        selector_params=selector_params,\n",
    "        logger_params=logger_params,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        test_dataloader=test_dataloader,\n",
    "        reg_coef=reg_coef,\n",
    "        disable_projection=False,\n",
    "        max_epochs=max_epochs,\n",
    "        load_path=previous_segment_path\n",
    "    )\n",
    "    segment_path = f'data/trained.model.{segment}.0'\n",
    "    torch.save(selector.state_dict(), segment_path)\n",
    "    logs.append(out)\n",
    "    previous_segment_path = segment_path\n",
    "\n",
    "dflogs = pd.DataFrame(logs)\n",
    "dflogs.to_csv('data/traininglogs.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp1env",
   "language": "python",
   "name": "exp1env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
